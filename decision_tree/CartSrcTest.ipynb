{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "datas.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e3538871170c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mdata_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[0mdecistion_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_decision_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgini\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e3538871170c>\u001b[0m in \u001b[0;36mload_csv\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datas.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"str\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[0mdata_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvert_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xueshangling\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xueshangling\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\xueshangling\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    622\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 623\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: datas.csv not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tree(object):\n",
    "    def __init__(self, value=None, true_branch=None, false_branch=None, results=None, col=-1, summary=None, data=None):\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.results = results\n",
    "        self.col = col\n",
    "        self.summary = summary\n",
    "        self.data = data\n",
    "    def __str__(self):\n",
    "        print(self.col, self.value)\n",
    "        print(self.results)\n",
    "        print(self.summary)\n",
    "        return \"\"\n",
    "def split_datas(rows, value, column):\n",
    "    \"\"\"\n",
    "    根据条件分离数据集\n",
    "    :param rows:\n",
    "    :param value:\n",
    "    :param column:\n",
    "    :return:  (list1, list2)\n",
    "    \"\"\"\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        for row in rows:\n",
    "            if row[column] >= value:\n",
    "                list1.append(row)\n",
    "            else:\n",
    "                list2.append(row)\n",
    "    else:\n",
    "        for row in rows:\n",
    "            if row[column] == value:\n",
    "                list1.append(row)\n",
    "            else:\n",
    "                list2.append(row)\n",
    "    return list1, list2\n",
    "def calculate_diff_count(data_set):\n",
    "    \"\"\"\n",
    "    分类统计data_set中每个类别的数量\n",
    "    :param datas:如：[[5.1, 3.5, 1.4, 0.2, 'setosa'], [4.9, 3, 1.4, 0.2, 'setosa'],....]\n",
    "    :return: 如：{'setosa': 50, 'versicolor': 50, 'virginica': 50}\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for data in data_set:\n",
    "        # 数据的最后一列data[-1]是类别\n",
    "        if data[-1] not in results:\n",
    "            results.setdefault(data[-1], 1)\n",
    "        else:\n",
    "            results[data[-1]] += 1\n",
    "    return results\n",
    "def gini(data_set):\n",
    "    \"\"\"\n",
    "    计算gini的值，即Gini(p)\n",
    "    :param data_set: 如：[[5.1, 3.5, 1.4, 0.2, 'setosa'], [4.9, 3, 1.4, 0.2, 'setosa'],....]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    length = len(data_set)\n",
    "    category_2_cnt = calculate_diff_count(data_set)\n",
    "    sum = 0.0\n",
    "    for category in category_2_cnt:\n",
    "        sum += pow(float(category_2_cnt[category]) / length, 2)\n",
    "    return 1 - sum\n",
    "def build_decision_tree(data_set, evaluation_function=gini):\n",
    "    \"\"\"\n",
    "    递归建立决策树，当gain=0时，停止回归\n",
    "    :param data_set: 如：[[5.1, 3.5, 1.4, 0.2, 'setosa'], [4.9, 3, 1.4, 0.2, 'setosa'],....]\n",
    "    :param evaluation_function:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    current_gain = evaluation_function(data_set)\n",
    "    column_length = len(data_set[0])\n",
    "    rows_length = len(data_set)\n",
    "    best_gain = 0.0\n",
    "    best_value = None\n",
    "    best_set = None\n",
    "    # choose the best gain\n",
    "    for feature_idx in range(column_length - 1):\n",
    "        feature_value_set = set(row[feature_idx] for row in data_set)\n",
    "        for feature_value in feature_value_set:\n",
    "            sub_data_set1, sub_data_set2 = split_datas(data_set, feature_value, feature_idx)\n",
    "            p = float(len(sub_data_set1)) / rows_length\n",
    "            # Gini(D,A)表示在特征A的条件下集合D的基尼指数，gini_d_a越小，样本集合不确定性越小\n",
    "            # 我们的目的是找到另gini_d_a最小的特征，及gain最大的特征\n",
    "            gini_d_a = p * evaluation_function(sub_data_set1) + (1 - p) * evaluation_function(sub_data_set2)\n",
    "            gain = current_gain - gini_d_a\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_value = (feature_idx, feature_value)\n",
    "                best_set = (sub_data_set1, sub_data_set2)\n",
    "    dc_y = {'impurity': '%.3f' % current_gain, 'sample': '%d' % rows_length}\n",
    "    # stop or not stop\n",
    "    if best_gain > 0:\n",
    "        true_branch = build_decision_tree(best_set[0], evaluation_function)\n",
    "        false_branch = build_decision_tree(best_set[1], evaluation_function)\n",
    "        return Tree(col=best_value[0], value=best_value[1], true_branch=true_branch, false_branch=false_branch, summary=dc_y)\n",
    "    else:\n",
    "        return Tree(results=calculate_diff_count(data_set), summary=dc_y, data=data_set)\n",
    "def prune(tree, mini_gain, evaluation_function=gini):\n",
    "    \"\"\"\n",
    "    裁剪\n",
    "    :param tree:\n",
    "    :param mini_gain:\n",
    "    :param evaluation_function:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if tree.true_branch.results == None:\n",
    "        prune(tree.true_branch, mini_gain, evaluation_function)\n",
    "    if tree.false_branch.results == None:\n",
    "        prune(tree.false_branch, mini_gain, evaluation_function)\n",
    "    if tree.true_branch.results != None and tree.false_branch.results != None:\n",
    "        len1 = len(tree.true_branch.data)\n",
    "        len2 = len(tree.false_branch.data)\n",
    "        len3 = len(tree.true_branch.data + tree.false_branch.data)\n",
    "        p = float(len1) / (len1 + len2)\n",
    "        gain = evaluation_function(tree.true_branch.data + tree.false_branch.data) \\\n",
    "               - p * evaluation_function(tree.true_branch.data)\\\n",
    "               - (1 - p) * evaluation_function(tree.false_branch.data)\n",
    "        if gain < mini_gain:\n",
    "            # 当节点的gain小于给定的 mini Gain时则合并这两个节点\n",
    "            tree.data = tree.true_branch.data + tree.false_branch.data\n",
    "            tree.results = calculate_diff_count(tree.data)\n",
    "            tree.true_branch = None\n",
    "            tree.false_branch = None\n",
    "def classify(data, tree):\n",
    "    \"\"\"\n",
    "    分类\n",
    "    :param data:\n",
    "    :param tree:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        branch = None\n",
    "        v = data[tree.col]\n",
    "        if isinstance(v, int) or isinstance(v, float):\n",
    "            if v >= tree.value:\n",
    "                branch = tree.true_branch\n",
    "            else:\n",
    "                branch = tree.false_branch\n",
    "        else:\n",
    "            if v == tree.value:\n",
    "                branch = tree.true_branch\n",
    "            else:\n",
    "                branch = tree.false_branch\n",
    "        return classify(data, branch)\n",
    "    \n",
    "def load_csv():\n",
    "    def convert_types(s):\n",
    "        s = s.strip()\n",
    "        try:\n",
    "            return float(s) if '.' in s else int(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "    data = np.loadtxt(\"datas.csv\", dtype=\"str\", delimiter=\",\")\n",
    "    data = data[1:, :]\n",
    "    data_set = ([[convert_types(item) for item in row] for row in data])\n",
    "    return data_set\n",
    "if __name__ == '__main__':\n",
    "    data_set = load_csv()\n",
    "    print (data_set)\n",
    "    decistion_tree = build_decision_tree(data_set, evaluation_function=gini)\n",
    "    print (decistion_tree.results)\n",
    "    # prune(decistion_tree, 0.4)\n",
    "    print (classify([5.1,3.5,1.4,0.2], decistion_tree)) # setosa\n",
    "    print (classify([6.8,2.8,4.8,1.4], decistion_tree)) # versicolor\n",
    "    print (classify([6.8,3.2,5.9,2.3], decistion_tree)) # virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
