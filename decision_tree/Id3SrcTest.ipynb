{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from math import log\n",
    "import operator\n",
    "\n",
    "def create_data_set():\n",
    "    \"\"\"\n",
    "    创建样本数据\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    data_set = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return data_set, labels\n",
    "def calc_shannon_ent(data_set):\n",
    "    \"\"\"\n",
    "    计算信息熵\n",
    "    :param data_set: 如： [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num = len(data_set)  # n rows\n",
    "    # 为所有的分类类目创建字典\n",
    "    label_counts = {}\n",
    "    for feat_vec in data_set:\n",
    "        current_label = feat_vec[-1]  # 取得最后一列数据\n",
    "        if current_label not in label_counts.keys():\n",
    "            label_counts[current_label] = 0\n",
    "        label_counts[current_label] += 1\n",
    "    # 计算香浓熵\n",
    "    shannon_ent = 0.0\n",
    "    for key in label_counts:\n",
    "        prob = float(label_counts[key]) / num\n",
    "        shannon_ent = shannon_ent - prob * log(prob, 2)\n",
    "    return shannon_ent\n",
    "def split_data_set(data_set, axis, value):\n",
    "    \"\"\"\n",
    "    返回特征值等于value的子数据集，切该数据集不包含列（特征）axis\n",
    "    :param data_set:  待划分的数据集\n",
    "    :param axis: 特征索引\n",
    "    :param value: 分类值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ret_data_set = []\n",
    "    for feat_vec in data_set:\n",
    "        if feat_vec[axis] == value:\n",
    "            reduce_feat_vec = feat_vec[:axis]\n",
    "            reduce_feat_vec.extend(feat_vec[axis + 1:])\n",
    "            ret_data_set.append(reduce_feat_vec)\n",
    "    return ret_data_set\n",
    "def choose_best_feature_to_split(data_set):\n",
    "    \"\"\"\n",
    "    按照最大信息增益划分数据\n",
    "    :param data_set: 样本数据，如： [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_feature = len(data_set[0]) - 1 # 特征个数，如：不浮出水面是否可以生存  和是否有脚蹼\n",
    "    base_entropy = calc_shannon_ent(data_set) # 经验熵H(D)\n",
    "    best_info_gain = 0\n",
    "    best_feature_idx = -1\n",
    "    for feature_idx in range(num_feature):\n",
    "        feature_val_list = [number[feature_idx] for number in data_set]  # 得到某个特征下所有值（某列）\n",
    "        unique_feature_val_list = set(feature_val_list)  # 获取无重复的属性特征值\n",
    "        new_entropy = 0\n",
    "        for feature_val in unique_feature_val_list:\n",
    "            sub_data_set = split_data_set(data_set, feature_idx, feature_val)\n",
    "            prob = len(sub_data_set) / float(len(data_set)) # 即p(t)\n",
    "            new_entropy += prob * calc_shannon_ent(sub_data_set) #对各子集香农熵求和\n",
    "        info_gain = base_entropy - new_entropy # 计算信息增益，g(D,A)=H(D)-H(D|A)\n",
    "        # 最大信息增益\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature_idx = feature_idx\n",
    "    return best_feature_idx\n",
    "def majority_cnt(class_list):\n",
    "    \"\"\"\n",
    "    统计每个类别出现的次数，并按大到小排序，返回出现次数最大的类别标签\n",
    "    :param class_list: 类数组\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_count = {}\n",
    "    for vote in class_list:\n",
    "        if vote not in class_count.keys():\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(1), reversed=True)\n",
    "    print (sorted_class_count[0][0])\n",
    "    return sorted_class_count[0][0]\n",
    "def create_tree(data_set, labels):\n",
    "    \"\"\"\n",
    "    构建决策树\n",
    "    :param data_set: 数据集合，如： [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "    :param labels: 标签数组，如：['no surfacing', 'flippers']\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    class_list = [sample[-1] for sample in data_set] # ['yes', 'yes', 'no', 'no', 'no']\n",
    "    # 类别相同，停止划分\n",
    "    if class_list.count(class_list[-1]) == len(class_list):\n",
    "        return class_list[-1]\n",
    "    # 长度为1，返回出现次数最多的类别\n",
    "    if len(class_list[0]) == 1:\n",
    "        return majority_cnt((class_list))\n",
    "    # 按照信息增益最高选取分类特征属性\n",
    "    best_feature_idx = choose_best_feature_to_split(data_set)  # 返回分类的特征的数组索引\n",
    "    best_feat_label = labels[best_feature_idx]  # 该特征的label\n",
    "    my_tree = {best_feat_label: {}}  # 构建树的字典\n",
    "    del (labels[best_feature_idx])  # 从labels的list中删除该label，相当于待划分的子标签集\n",
    "    feature_values = [example[best_feature_idx] for example in data_set]\n",
    "    unique_feature_values = set(feature_values)\n",
    "    for feature_value in unique_feature_values:\n",
    "        sub_labels = labels[:]  # 子集合\n",
    "        # 构建数据的子集合，并进行递归\n",
    "        sub_data_set = split_data_set(data_set, best_feature_idx, feature_value) # 待划分的子数据集\n",
    "        my_tree[best_feat_label][feature_value] = create_tree(sub_data_set, sub_labels)\n",
    "    return my_tree\n",
    "def classify(input_tree, feat_labels, test_vec):\n",
    "    \"\"\"\n",
    "    决策树分类\n",
    "    :param input_tree: 决策树\n",
    "    :param feat_labels: 特征标签\n",
    "    :param test_vec: 测试的数据\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    first_str = list(input_tree.keys())[0]  # 获取树的第一特征属性\n",
    "    second_dict = input_tree[first_str]  # 树的分子，子集合Dict\n",
    "    feat_index = feat_labels.index(first_str)  # 获取决策树第一层在feat_labels中的位置\n",
    "    for key in second_dict.keys():\n",
    "        if test_vec[feat_index] == key:\n",
    "            if type(second_dict[key]).__name__ == 'dict':\n",
    "                class_label = classify(second_dict[key], feat_labels, test_vec)\n",
    "            else:\n",
    "                class_label = second_dict[key]\n",
    "            return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树： {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}\n",
      "（1）不浮出水面可以生存，无脚蹼： no\n",
      "（2）不浮出水面可以生存，有脚蹼： yes\n",
      "（3）不浮出水面可以不能生存，无脚蹼： no\n"
     ]
    }
   ],
   "source": [
    "data_set, labels = create_data_set()\n",
    "decision_tree = create_tree(data_set, labels)\n",
    "print (\"决策树：\", decision_tree)\n",
    "data_set, labels = create_data_set()\n",
    "print (\"（1）不浮出水面可以生存，无脚蹼：\", classify(decision_tree, labels, [1, 0]))\n",
    "print (\"（2）不浮出水面可以生存，有脚蹼：\", classify(decision_tree, labels, [1, 1]))\n",
    "print (\"（3）不浮出水面可以不能生存，无脚蹼：\", classify(decision_tree, labels, [0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
